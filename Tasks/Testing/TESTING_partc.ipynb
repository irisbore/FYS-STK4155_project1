{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c): Adding Lasso for the Franke function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import functions as f\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a standardized dataset \n",
    "#np.random.seed(2024)\n",
    "\n",
    "#x = np.arange(0, 1, 0.05)\n",
    "#y = np.arange(0, 1, 0.05)\n",
    "#z = f.FrankeFunction(x, y)\n",
    "#z = z + np.random.randn(z.shape[0])\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 50\n",
    "x = np.random.rand(N)\n",
    "y = np.random.randn(N)\n",
    "z = f.FrankeFunction(x,y) #Using x,y and z when doing regression\n",
    "z = z + np.random.normal(0, 0.1, z.shape) #the noise was too high, tried sligtly less\n",
    "#Creating lambda values avoiding \"b\" in the name as it is a reserved keyword in python\n",
    "#lamda = np.array([0.1,0.01,0.001,0.0001,0.00001])  # Try values in a small range\n",
    "lamda = np.logspace(-6, -1, 6)\n",
    "print(lamda)\n",
    "\n",
    "degrees = np.arange(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Empty lists to store scores and parameters\n",
    "beta_lasso_values = []\n",
    "mse_lasso_scores = []\n",
    "r2_lasso_scores = []\n",
    "\n",
    "# Looping through each lambda\n",
    "for i in range(np.size(lamda)):\n",
    "    # Polynomial degrees\n",
    "\n",
    "    # Appending lists to store scores and parameters\n",
    "    beta_lasso_values.append([])\n",
    "    mse_lasso_scores.append([])\n",
    "    r2_lasso_scores.append([])\n",
    "\n",
    "\n",
    "    # Looping through each degree\n",
    "    for degree in degrees:\n",
    "\n",
    "        # Creating design matrix\n",
    "        #X = create_design_matrix(x, degree)\n",
    "        poly_features = PolynomialFeatures(degree=degree)\n",
    "        X = poly_features.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "        # Split the data into training and test data\n",
    "        X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale and center the data\n",
    "        scaler = StandardScaler(with_std=True, with_mean=False)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Create and fit the linear regression model\n",
    "        model = Lasso(alpha = lamda[i], fit_intercept=False, max_iter=100000)\n",
    "        model.fit(X_train, z_train)\n",
    "        \n",
    "        # Make predictions for training and test data\n",
    "        z_train_pred = model.predict(X_train)\n",
    "        z_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Getting the coefficients (beta values)\n",
    "        beta_lasso = model.coef_\n",
    "\n",
    "        # Compute mean squared error for training and test data\n",
    "        mse_train = mean_squared_error(z_train, z_train_pred)\n",
    "        mse_test = mean_squared_error(z_test, z_test_pred)\n",
    "\n",
    "        # Compute R2 score for training and test data\n",
    "        r2_train = r2_score(z_train, z_train_pred)\n",
    "        r2_test = r2_score(z_test, z_test_pred)\n",
    "        \n",
    "        # Appending beta values and scores\n",
    "        beta_lasso_values[i].append(beta_lasso)\n",
    "        mse_lasso_scores[i].append(mse_test)\n",
    "        r2_lasso_scores[i].append(r2_test)\n",
    "\n",
    "#print(beta_lasso_values)\n",
    "#print(mse_lasso_scores)\n",
    "#print(r2_lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MSE and R2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE as a function of Polynomial Degree')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 as a function of Polynomial Degree')\n",
    "\n",
    "for j in range(np.size(lamda)):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(degrees, mse_lasso_scores[j], marker='o', label=f'Lambda = {lamda[j]:.5f}')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(degrees, r2_lasso_scores[j], marker='o', label=f'Lambda = {lamda[j]:.5f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(fname=\"../../results/ridge_error_degree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting beta values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Beta Values')\n",
    "plt.title('Beta Values as a function of Polynomial Degree')\n",
    "\n",
    "#colors = ['red', 'blue', 'green', 'orange', 'purple']  # Define colors for each lambda\n",
    "\n",
    "for i in range(len(beta_lasso_values)):\n",
    "    for j in range(len(beta_lasso_values[i])):\n",
    "        for k in range(len(beta_lasso_values[i][j])):\n",
    "            beta_i = beta_lasso_values[i][j][k]\n",
    "            plt.plot(degrees[j]*np.ones_like(beta_lasso_values[i][j][k]), beta_lasso_values[i][j][k], marker='o', label= f'Lambda = {lamda[i]:.5f}' if k == 0 else None)  # Use color based on lambda color=colors[i]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', label=f'Lambda = {lamda[i]:.5f}', markersize=8) for i in range(len(lamda))]) #, markerfacecolor=colors[i\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell a \"critical discussion of the three methods and a judgement of which model fits the data best\" is required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
