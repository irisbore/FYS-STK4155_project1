{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "import git\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "path_to_root = git.Repo(\".\", search_parent_directories=True).working_dir\n",
    "sys.path.append(path_to_root+'/src'+'/')\n",
    "import functions as f\n",
    "import load_data as ld\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstraping and Bias Variance tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain data\n",
    "terrain_data = imread(path_to_root+\"/data/SRTM_data_Norway_1.tif\")\n",
    "\n",
    "# Define the x and y coordinates\n",
    "x = np.arange(0, terrain_data.shape[1], 10)\n",
    "y = np.arange(0, terrain_data.shape[0], 10)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "x= xv.flatten()\n",
    "y= yv.flatten()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# Sample z\n",
    "#zv = terrain_data[2000:3601:10, ::10]\n",
    "zv = terrain_data[::10, ::10]\n",
    "z = zv.flatten().reshape(-1, 1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boostraps = 100\n",
    "degree = np.arange(0, 15)\n",
    "\n",
    "# Make data set\n",
    "#x, y, z = ld.load_uniform_data(N_samples = 1000)\n",
    "\n",
    "errortest = np.zeros(len(degree))\n",
    "errortrain = np.zeros(len(degree))  \n",
    "bias = np.zeros(len(degree))\n",
    "variance = np.zeros(len(degree))\n",
    "\n",
    "for i in degree:\n",
    "    # Combine x transformation and model into one operation.\n",
    "    #X = f.create_design_matrix(x, y, i)\n",
    "    design_matrix = PolynomialFeatures(degree=i)\n",
    "    X = design_matrix.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # Splitting the data into training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2)\n",
    "\n",
    "    # Scale and center the data\n",
    "    X_train, X_test = f.scale_train_test(train = X_train, test = X_test)\n",
    "    z_train, z_test = f.scale_train_test(train = z_train, test = z_test)\n",
    "\n",
    "    # Fit the model\n",
    "    ols = LinearRegression(fit_intercept=False)\n",
    "    ridge = Ridge(alpha=0.0001, fit_intercept=False)   \n",
    "    lasso = Lasso(alpha=0.0001, fit_intercept=False)\n",
    "\n",
    "    model = ols # Change this variable if you want to use another model\n",
    "\n",
    "    # The following (m x n_bootstraps) matrix holds the column vectors y_pred\n",
    "    # for each bootstrap iteration.\n",
    "    z_pred = np.zeros((z_test.shape[0], n_boostraps))\n",
    "\n",
    "    for j in range(n_boostraps):\n",
    "        X_, z_ = resample(X_train, z_train)\n",
    "\n",
    "        # Evaluate the new model on the same test data each time.\n",
    "        z_pred[:, j] = model.fit(X_, z_).predict(X_test).ravel() \n",
    "\n",
    "        # Note: Expectations and variances taken w.r.t. different training\n",
    "        # data sets, hence the axis=1. Subsequent means are taken across the test data\n",
    "        # set in order to obtain a total value, but before this we have error/bias/variance\n",
    "        # calculated per data point in the test set.\n",
    "        # Note 2: The use of keepdims=True is important in the calculation of bias as this \n",
    "        # maintains the column vector form. Dropping this yields very unexpected results.\n",
    "\n",
    "    errortest[i] = np.mean( np.mean((z_test - z_pred)**2, axis=1, keepdims=True) )\n",
    "    errortrain[i] = np.mean( np.mean((z_train - ols.fit(X_train, z_train).predict(X_train))**2, axis=1, keepdims=True ) ) # modelols.fit(X_train, z_train).predict(X_train))**2 ) ?\n",
    "    bias[i] = np.mean( (z_test - np.mean(z_pred, axis=1, keepdims=True))**2 )\n",
    "    variance[i] = np.mean( np.var(z_pred, axis=1, keepdims=True) )\n",
    "\n",
    "\n",
    "plt.title(f'Bias variance tradeoff for OLS')\n",
    "plt.xlabel('Model complexity (degree)')\n",
    "plt.ylabel('Error')\n",
    "plt.plot(degree, errortest, label='Error')\n",
    "plt.plot(degree, bias, label='Bias')\n",
    "plt.plot(degree, variance, label='Variance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(degree, errortrain, label=\"Training Sample\", color='teal', linewidth=2)\n",
    "plt.plot(degree, errortest, label=\"Test Sample\", color='red', linewidth=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Model Complexity\")\n",
    "plt.ylabel(\"Prediction Error\")\n",
    "plt.title(\"Test and Training Error as a function of Model Complexity\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain data\n",
    "terrain_data = imread(path_to_root+\"/data/SRTM_data_Norway_1.tif\")\n",
    "\n",
    "# Define the x and y coordinates\n",
    "x = np.arange(0, terrain_data.shape[1], 10)\n",
    "y = np.arange(0, terrain_data.shape[0], 10)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "x= xv.flatten()\n",
    "y= yv.flatten()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# Sample z\n",
    "#zv = terrain_data[2000:3601:10, ::10]\n",
    "zv = terrain_data[::10, ::10]\n",
    "z = zv.flatten().reshape(-1, 1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your data (ensure ld.load_uniform_data() is defined)\n",
    "#x, y, z = ld.load_uniform_data()\n",
    "\n",
    "# Define the range of polynomial degrees to test\n",
    "degrees = np.arange(1, 10)  # Start from degree 1 to avoid intercept-only model\n",
    "\n",
    "# Define the number of folds\n",
    "k_folds = 10\n",
    "\n",
    "# Initialize arrays to store the MSE values\n",
    "mse_ols = np.zeros_like(degrees, dtype=float)\n",
    "mse_ridge = np.zeros_like(degrees, dtype=float)\n",
    "mse_lasso = np.zeros_like(degrees, dtype=float)\n",
    "\n",
    "# Define lambda values for Ridge and Lasso\n",
    "lambda_values = np.logspace(-5, 2, 8)  # From 1e-5 to 1e2\n",
    "\n",
    "# Perform k-fold cross-validation for each degree\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X = poly_features.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # No need to scale here; include scaling in the pipeline\n",
    "\n",
    "    # OLS Model with Pipeline\n",
    "    pipeline_ols = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearRegression(fit_intercept=False))\n",
    "    ])\n",
    "    mse_ols[i] = -np.mean(cross_val_score(pipeline_ols, X, z, cv=k_folds, scoring='neg_mean_squared_error'))\n",
    "\n",
    "    # Ridge Regression\n",
    "    mse_temp_ridge = []\n",
    "    for lambda_val in lambda_values:\n",
    "        pipeline_ridge = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Ridge(alpha=lambda_val, fit_intercept=False))\n",
    "        ])\n",
    "        mse = -np.mean(cross_val_score(pipeline_ridge, X, z, cv=k_folds, scoring='neg_mean_squared_error'))\n",
    "        mse_temp_ridge.append(mse)\n",
    "    mse_ridge[i] = np.min(mse_temp_ridge)\n",
    "\n",
    "    # Lasso Regression\n",
    "    mse_temp_lasso = []\n",
    "    for lambda_val in lambda_values:\n",
    "        pipeline_lasso = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Lasso(alpha=lambda_val, fit_intercept=False, max_iter=10000))\n",
    "        ])\n",
    "        mse = -np.mean(cross_val_score(pipeline_lasso, X, z, cv=k_folds, scoring='neg_mean_squared_error'))\n",
    "        mse_temp_lasso.append(mse)\n",
    "    mse_lasso[i] = np.min(mse_temp_lasso)\n",
    "\n",
    "# Plot the MSE values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(degrees, mse_ols, label='OLS')\n",
    "plt.plot(degrees, mse_ridge, label='Ridge')\n",
    "plt.plot(degrees, mse_lasso, label='Lasso')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE for OLS, Ridge, and Lasso')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
