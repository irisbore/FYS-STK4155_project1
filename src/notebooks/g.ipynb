{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part g): Analysis of real data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import git\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import functions as f\n",
    "path_to_root = git.Repo(\".\", search_parent_directories=True).working_dir\n",
    "sys.path.append(path_to_root)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import terrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain\n",
    "terrain1 = imread(path_to_root+\"/data/SRTM_data_Norway_1.tif\")\n",
    "# Show the terrain\n",
    "plt.figure()\n",
    "plt.title(\"Terrain over Norway 1\")\n",
    "plt.imshow(terrain1, cmap=\"gray\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()\n",
    "print(terrain1.shape)\n",
    "print(type(terrain1))\n",
    "terrain1[2000:3601,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of terrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain data\n",
    "terrain_data = imread(path_to_root+\"/data/SRTM_data_Norway_1.tif\")\n",
    "\n",
    "# Define the x and y coordinates\n",
    "#x = np.arange(0, terrain_data[2000:3601,:].shape[1], 10)\n",
    "x = np.arange(0, terrain_data.shape[1], 10)\n",
    "#y = np.arange(0, terrain_data[2000:3601,:].shape[0], 10)\n",
    "y = np.arange(0, terrain_data.shape[0], 10)\n",
    "# Create a meshgrid of the x and y coordinates\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "# Sample z\n",
    "#zv = terrain_data[2000:3601:10, ::10]\n",
    "zv = terrain_data[::10, ::10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "#ax = fig.gca(projection='3d')\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(xv, yv, zv, cmap=cm.coolwarm,\n",
    "linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "#ax.set_zlim(0,2000)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter(\"%.02f\"))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xv.flatten()\n",
    "y = yv.flatten()\n",
    "z = zv.flatten().reshape(-1, 1)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "aspect_ratio = xv.shape[1] / yv.shape[0]\n",
    "plt.figure(figsize=(5, 5 / aspect_ratio))\n",
    "\n",
    "heatmap = plt.pcolormesh(xv, yv, zv, shading='auto', cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(heatmap)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Heatmap of sampled terrain data')\n",
    "plt.gca().invert_yaxis()\n",
    "# Show the plot\n",
    "#f.save_to_results(filename = \"sampled_data_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(1, 15)\n",
    "\n",
    "beta_values = []\n",
    "mse_values = np.zeros(len(degrees))\n",
    "R2_values = np.zeros(len(degrees))\n",
    "\n",
    "for i, degree in enumerate(degrees): \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X = poly_features.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # Split the data into training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale and center the data\n",
    "    X_train, X_test = f.scale_train_test(train = X_train, test = X_test)\n",
    "    z_train, z_test = f.scale_train_test(train = z_train, test = z_test)\n",
    "\n",
    "    #Calculating OLSbeta, ztilde, mse and R2\n",
    "    OLSbeta = f.beta_OLS(X_train, z_train)\n",
    "    ztilde = f.z_predict(X_test, OLSbeta)\n",
    "    mse = f.mse(z_test, ztilde)\n",
    "    R2 = f.r2(z_test, ztilde)\n",
    "\n",
    "    #Adding the values to the arrays\n",
    "\n",
    "    beta_values.append(OLSbeta)\n",
    "    mse_values[i] = mse\n",
    "    R2_values[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MSE and R2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(degrees, mse_values, marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE as a function of Polynomial Degree for OLS')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(degrees, R2_values, marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 as a function of Polynomial Degree for OLS')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the estimated z_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the latest prediction as it has the best score \n",
    "ztilde = f.z_predict(X, OLSbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X = X_scaler.transform(X)\n",
    "\n",
    "z_scaler = StandardScaler()\n",
    "#z_train = z_scaler.fit_transform(z_train)\n",
    "#z_test = z_scaler.transform(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztildev = ztilde.flatten()\n",
    "print(ztilde.shape)\n",
    "ztildev = ztilde.reshape(361, 181)\n",
    "print(ztildev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have to scale the betavalues back? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "#aspect_ratio = xv.shape[1] / yv.shape[0]\n",
    "#plt.figure(figsize=(5, 5 / aspect_ratio))\n",
    "\n",
    "heatmap = plt.pcolormesh(xv, yv, ztildev, cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(heatmap)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Heatmap of sampled terrain data')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree, values in enumerate(beta_values):\n",
    "    print(\"degree\", degree, \"betavalues\", len(values))\n",
    "    print(values)\n",
    "    print(\" \")\n",
    "    degrees = np.repeat(degree, len(values))\n",
    "    plt.scatter(degrees, values)\n",
    "\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Beta Values')\n",
    "plt.title('Beta values as a function of a Polynomial Degree for OLS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degrees = np.arange(1, 15)\n",
    "\n",
    "beta_ridge_values = []\n",
    "mse_ridge_values = np.zeros(len(degrees))\n",
    "R2_ridge_values = np.zeros(len(degrees))\n",
    "\n",
    "lambda_values = np.logspace(-5, 3, 9)\n",
    "\n",
    "for i, degree in enumerate(degrees): \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X = poly_features.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # Split the data into training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale and center the data\n",
    "    X_train, X_test = f.scale_train_test(train = X_train, test = X_test)\n",
    "    z_train, z_test = f.scale_train_test(train = z_train, test = z_test)\n",
    "\n",
    "    mse_temp = np.zeros(len(lambda_values))\n",
    "    for j, lambda_ in enumerate(lambda_values):\n",
    "        #Calculating OLSbeta, ztilde, mse and R2\n",
    "        Ridgebeta = f.beta_ridge(X_train, z_train, lambda_)\n",
    "        ztilde = f.z_predict(X_test, Ridgebeta)\n",
    "        mse = f.mse(z_test, ztilde)\n",
    "        mse_temp[j] = mse\n",
    "\n",
    "    j = np.argmin(mse_temp)\n",
    "    Ridgebeta = f.beta_ridge(X_train, z_train, lambda_values[j])\n",
    "    ztilde = f.z_predict(X_test, Ridgebeta)\n",
    "\n",
    "    #Adding the values to the arrays\n",
    "    beta_ridge_values.append(Ridgebeta)\n",
    "    mse_ridge_values[i] = f.mse(z_test, ztilde)\n",
    "    R2_ridge_values[i] = f.r2(z_test, ztilde)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MSE and R2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(degrees, mse_ridge_values, marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE as a function of Polynomial Degree for Ridge')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(degrees, R2_ridge_values, marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 as a function of Polynomial Degree for Ridge')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree, values in enumerate(beta_ridge_values):\n",
    "    print(\"degree\", degree, \"betavalues\", len(values))\n",
    "    print(values)\n",
    "    print(\" \")\n",
    "    degrees = np.repeat(degree, len(values))\n",
    "    plt.scatter(degrees, values)\n",
    "\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Beta Values')\n",
    "plt.title('Beta values as a function of a Polynomial Degree for Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the estimated z_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the latest prediction as it has the best score \n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X = X_scaler.transform(X)\n",
    "\n",
    "z_scaler = StandardScaler()\n",
    "z_scaler.fit(z_train)\n",
    "ztilde = z_scaler.inverse_transform(ztilde)\n",
    "ztilde = f.z_predict(X, Ridgebeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztildev = ztilde.flatten()\n",
    "print(ztilde.shape)\n",
    "ztildev = ztilde.reshape(361, 181)\n",
    "print(ztildev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap\n",
    "#aspect_ratio = xv.shape[1] / yv.shape[0]\n",
    "#plt.figure(figsize=(5, 5 / aspect_ratio))\n",
    "\n",
    "heatmap = plt.pcolormesh(xv, yv, ztildev, cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(heatmap)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Heatmap of sampled terrain data')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(1, 9)\n",
    "\n",
    "beta_lasso_values = []\n",
    "mse_lasso_values = np.zeros(len(degrees))\n",
    "R2_lasso_values = np.zeros(len(degrees))\n",
    "\n",
    "lambda_values = np.logspace(-5, -3, 2)\n",
    "\n",
    "for i, degree in enumerate(degrees): \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X = poly_features.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # Split the data into training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale and center the data\n",
    "    X_train, X_test = f.scale_train_test(train = X_train, test = X_test)\n",
    "    z_train, z_test = f.scale_train_test(train = z_train, test = z_test)\n",
    "    \n",
    "    mse_temp = np.zeros(len(lambda_values))\n",
    "\n",
    "    for j, lambda_ in enumerate(lambda_values):\n",
    "        # Create and fit the linear regression model\n",
    "        model = Lasso(alpha = lambda_values[j], tol = 1e-2, selection = 'random', precompute=True, fit_intercept=False, max_iter=10000) #selection = \"random\"\n",
    "        model.fit(X_train, z_train)\n",
    "\n",
    "        # Make predictions for training and test data\n",
    "        z_train_pred = model.predict(X_train)\n",
    "        z_test_pred = model.predict(X_test)\n",
    "        #print(z_train_pred.shape)\n",
    "\n",
    "        # Compute mean squared error for training and test data\n",
    "        #mse_train = f.mse(z_train, z_train_pred)\n",
    "        mse_test = f.r2(z_test, z_test_pred)\n",
    "\n",
    "        mse_temp[j] = mse_test\n",
    "\n",
    "    j = np.argmin(mse_temp)\n",
    "    print(lambda_values[j])\n",
    "     # Create and fit the linear regression model with the optimal lambda value\n",
    "    model = Lasso(alpha = lambda_values[j], tol = 1e-2, selection = 'random', precompute=True, fit_intercept=False, max_iter=10000)\n",
    "    model.fit(X_train, z_train)\n",
    "\n",
    "    # Make predictions for training and test data\n",
    "    z_train_pred = model.predict(X_train)\n",
    "    z_test_pred = model.predict(X_test)\n",
    "\n",
    "    Lassobeta = model.coef_\n",
    "\n",
    "    #Adding the values to the arrays\n",
    "    beta_lasso_values.append(Lassobeta)\n",
    "    mse_lasso_values[i] = f.mse(z_test, z_test_pred)\n",
    "    R2_lasso_values[i] = f.r2(z_test, z_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MSE and R2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(degrees, mse_lasso_values, marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE as a function of Polynomial Degree for Lasso')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(degrees, R2_lasso_values, marker='o')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 as a function of Polynomial Degree for Lasso')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree, values in enumerate(beta_lasso_values):\n",
    "    print(\"degree\", degree, \"betavalues\", len(values))\n",
    "    print(values)\n",
    "    print(\" \")\n",
    "    degrees = np.repeat(degree, len(values))\n",
    "    plt.scatter(degrees, values)\n",
    "\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Beta Values')\n",
    "plt.title('Beta values as a function of a Polynomial Degree for Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting OLS and Ridge together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(1, 30)\n",
    "# Plotting MSE and R2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(degrees, mse_values, marker='o', label='OLS')\n",
    "plt.plot(degrees, mse_ridge_values, marker='o', label='Ridge')\n",
    "#plt.plot(degrees, mse_lasso_values, marker='o', label='Lasso')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE as a function of Polynomial Degree')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(degrees, R2_values, marker='o', label='OLS')\n",
    "plt.plot(degrees, R2_ridge_values, marker='o', label='Ridge')\n",
    "#plt.plot(degrees, R2_lasso_values, marker='o', label='Lasso')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 as a function of Polynomial Degree')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "import git\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "path_to_root = git.Repo(\".\", search_parent_directories=True).working_dir\n",
    "sys.path.append(path_to_root+'/src'+'/')\n",
    "import functions as f\n",
    "import load_data as ld\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstraping and Bias Variance tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain data\n",
    "terrain_data = imread(path_to_root+\"/data/SRTM_data_Norway_1.tif\")\n",
    "\n",
    "# Define the x and y coordinates\n",
    "x = np.arange(0, terrain_data.shape[1], 10)\n",
    "y = np.arange(0, terrain_data.shape[0], 10)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "x= xv.flatten()\n",
    "y= yv.flatten()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# Sample z\n",
    "#zv = terrain_data[2000:3601:10, ::10]\n",
    "zv = terrain_data[::10, ::10]\n",
    "z = zv.flatten().reshape(-1, 1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boostraps = 100\n",
    "degree = np.arange(0, 15)\n",
    "\n",
    "# Make data set\n",
    "#x, y, z = ld.load_uniform_data(N_samples = 1000)\n",
    "\n",
    "errortest = np.zeros(len(degree))\n",
    "errortrain = np.zeros(len(degree))  \n",
    "bias = np.zeros(len(degree))\n",
    "variance = np.zeros(len(degree))\n",
    "\n",
    "for i in degree:\n",
    "    # Combine x transformation and model into one operation.\n",
    "    #X = f.create_design_matrix(x, y, i)\n",
    "    design_matrix = PolynomialFeatures(degree=i)\n",
    "    X = design_matrix.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # Splitting the data into training and test data\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2)\n",
    "\n",
    "    # Scale and center the data\n",
    "    X_train, X_test = f.scale_train_test(train = X_train, test = X_test)\n",
    "    z_train, z_test = f.scale_train_test(train = z_train, test = z_test)\n",
    "\n",
    "    # Fit the model\n",
    "    ols = LinearRegression(fit_intercept=False)\n",
    "    ridge = Ridge(alpha=0.0001, fit_intercept=False)   \n",
    "    lasso = Lasso(alpha=0.0001, fit_intercept=False)\n",
    "\n",
    "    model = ols # Change this variable if you want to use another model\n",
    "\n",
    "    # The following (m x n_bootstraps) matrix holds the column vectors y_pred\n",
    "    # for each bootstrap iteration.\n",
    "    z_pred = np.zeros((z_test.shape[0], n_boostraps))\n",
    "\n",
    "    for j in range(n_boostraps):\n",
    "        X_, z_ = resample(X_train, z_train)\n",
    "\n",
    "        # Evaluate the new model on the same test data each time.\n",
    "        z_pred[:, j] = model.fit(X_, z_).predict(X_test).ravel() \n",
    "\n",
    "        # Note: Expectations and variances taken w.r.t. different training\n",
    "        # data sets, hence the axis=1. Subsequent means are taken across the test data\n",
    "        # set in order to obtain a total value, but before this we have error/bias/variance\n",
    "        # calculated per data point in the test set.\n",
    "        # Note 2: The use of keepdims=True is important in the calculation of bias as this \n",
    "        # maintains the column vector form. Dropping this yields very unexpected results.\n",
    "\n",
    "    errortest[i] = np.mean( np.mean((z_test - z_pred)**2, axis=1, keepdims=True) )\n",
    "    errortrain[i] = np.mean( np.mean((z_train - ols.fit(X_train, z_train).predict(X_train))**2, axis=1, keepdims=True ) ) # modelols.fit(X_train, z_train).predict(X_train))**2 ) ?\n",
    "    bias[i] = np.mean( (z_test - np.mean(z_pred, axis=1, keepdims=True))**2 )\n",
    "    variance[i] = np.mean( np.var(z_pred, axis=1, keepdims=True) )\n",
    "\n",
    "\n",
    "plt.title(f'Bias variance tradeoff for OLS')\n",
    "plt.xlabel('Model complexity (degree)')\n",
    "plt.ylabel('Error')\n",
    "plt.plot(degree, errortest, label='Error')\n",
    "plt.plot(degree, bias, label='Bias')\n",
    "plt.plot(degree, variance, label='Variance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(degree, errortrain, label=\"Training Sample\", color='teal', linewidth=2)\n",
    "plt.plot(degree, errortest, label=\"Test Sample\", color='red', linewidth=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Model Complexity\")\n",
    "plt.ylabel(\"Prediction Error\")\n",
    "plt.title(\"Test and Training Error as a function of Model Complexity\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain data\n",
    "terrain_data = imread(path_to_root+\"/data/SRTM_data_Norway_1.tif\")\n",
    "\n",
    "# Define the x and y coordinates\n",
    "x = np.arange(0, terrain_data.shape[1], 10)\n",
    "y = np.arange(0, terrain_data.shape[0], 10)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "x= xv.flatten()\n",
    "y= yv.flatten()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# Sample z\n",
    "#zv = terrain_data[2000:3601:10, ::10]\n",
    "zv = terrain_data[::10, ::10]\n",
    "z = zv.flatten().reshape(-1, 1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your data (ensure ld.load_uniform_data() is defined)\n",
    "#x, y, z = ld.load_uniform_data()\n",
    "\n",
    "# Define the range of polynomial degrees to test\n",
    "degrees = np.arange(1, 10)  # Start from degree 1 to avoid intercept-only model\n",
    "\n",
    "# Define the number of folds\n",
    "k_folds = 10\n",
    "\n",
    "# Initialize arrays to store the MSE values\n",
    "mse_ols = np.zeros_like(degrees, dtype=float)\n",
    "mse_ridge = np.zeros_like(degrees, dtype=float)\n",
    "mse_lasso = np.zeros_like(degrees, dtype=float)\n",
    "\n",
    "# Define lambda values for Ridge and Lasso\n",
    "lambda_values = np.logspace(-5, 2, 8)  # From 1e-5 to 1e2\n",
    "\n",
    "# Perform k-fold cross-validation for each degree\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X = poly_features.fit_transform(np.column_stack((x, y)))\n",
    "\n",
    "    # No need to scale here; include scaling in the pipeline\n",
    "\n",
    "    # OLS Model with Pipeline\n",
    "    pipeline_ols = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearRegression(fit_intercept=False))\n",
    "    ])\n",
    "    mse_ols[i] = -np.mean(cross_val_score(pipeline_ols, X, z, cv=k_folds, scoring='neg_mean_squared_error'))\n",
    "\n",
    "    # Ridge Regression\n",
    "    mse_temp_ridge = []\n",
    "    for lambda_val in lambda_values:\n",
    "        pipeline_ridge = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Ridge(alpha=lambda_val, fit_intercept=False))\n",
    "        ])\n",
    "        mse = -np.mean(cross_val_score(pipeline_ridge, X, z, cv=k_folds, scoring='neg_mean_squared_error'))\n",
    "        mse_temp_ridge.append(mse)\n",
    "    mse_ridge[i] = np.min(mse_temp_ridge)\n",
    "    j = np.argmin(mse_temp_ridge)\n",
    "    print(f\"Degree {degree}: Best lambda value for Ridge = {lambda_values[j]}\")\n",
    "\n",
    "    # Lasso Regression\n",
    "    mse_temp_lasso = []\n",
    "    for lambda_val in lambda_values:\n",
    "        pipeline_lasso = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Lasso(alpha=lambda_val, fit_intercept=False, max_iter=10000))\n",
    "        ])\n",
    "        mse = -np.mean(cross_val_score(pipeline_lasso, X, z, cv=k_folds, scoring='neg_mean_squared_error'))\n",
    "        mse_temp_lasso.append(mse)\n",
    "    mse_lasso[i] = np.min(mse_temp_lasso)\n",
    "    j = np.argmin(mse_temp_lasso)\n",
    "    print(f\"Degree {degree}: Best lambda value for Lasso = {lambda_values[j]}\")\n",
    "\n",
    "# Plot the MSE values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(degrees, mse_ols, label='OLS')\n",
    "plt.plot(degrees, mse_ridge, label='Ridge')\n",
    "plt.plot(degrees, mse_lasso, label='Lasso')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE for OLS, Ridge, and Lasso')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
